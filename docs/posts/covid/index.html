<!DOCTYPE html>
<html
  dir="ltr"
  lang="en"
  data-theme=""
  
    class="html theme--light"
  
><head>
  <title>
    Allan Randall
        |
        Detecting COVID-19 and Pneumonia Using Transfer Learning
      

    

  </title>

  
  <meta charset="utf-8" /><meta name="generator" content="Hugo 0.105.0"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <meta name="author" content="Allan Randall" />
  <meta
    name="description"
    content="How I built a model to detect COVID-19 and Pneumonia with &gt;97% accuracy."
  />
  
  
    
    
    <link
      rel="stylesheet"
      href="/scss/main.min.afcf7a74c48633d6afc6447bf52d6af2c1bbc24b0cb0ce6d834cc98f49bfba77.css"
      integrity="sha256-r896dMSGM9avxkR79S1q8sG7wksMsM5tg0zJj0m/unc="
      crossorigin="anonymous"
      type="text/css"
    />
  

  
  <link
    rel="stylesheet"
    href="/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css"
    integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA="
    crossorigin="anonymous"
    type="text/css"
  />
  
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css"
    integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css"
    integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css"
    integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css"
    integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />

  <link rel="canonical" href="https://allanrandall.com/posts/covid/" />

  
  
  
  
  <script
    type="text/javascript"
    src="/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js"
    integrity="sha256-&#43;RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI="
    crossorigin="anonymous"
  ></script>

  
    
    
    <script
      type="text/javascript"
      src="/js/anatole-theme-switcher.min.d6d329d93844b162e8bed1e915619625ca91687952177552b9b3e211014a2957.js"
      integrity="sha256-1tMp2ThEsWLovtHpFWGWJcqRaHlSF3VSubPiEQFKKVc="
      crossorigin="anonymous"
    ></script>
  

  


  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Detecting COVID-19 and Pneumonia Using Transfer Learning"/>
<meta name="twitter:description" content="How I built a model to detect COVID-19 and Pneumonia with &gt;97% accuracy."/>



  
  <meta property="og:title" content="Detecting COVID-19 and Pneumonia Using Transfer Learning" />
<meta property="og:description" content="How I built a model to detect COVID-19 and Pneumonia with &gt;97% accuracy." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://allanrandall.com/posts/covid/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-02-23T20:38:00+11:00" />
<meta property="article:modified_time" content="2022-02-23T20:38:00+11:00" /><meta property="og:site_name" content="Allan Randall" />




  
  
  
  
  <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "articleSection": "posts",
        "name": "Detecting COVID-19 and Pneumonia Using Transfer Learning",
        "headline": "Detecting COVID-19 and Pneumonia Using Transfer Learning",
        "alternativeHeadline": "",
        "description": "
      How I built a model to detect COVID-19 and Pneumonia with \u003e97% accuracy.


    ",
        "inLanguage": "en",
        "isFamilyFriendly": "true",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/allanrandall.com\/posts\/covid\/"
        },
        "author" : {
            "@type": "Person",
            "name": "Allan Randall"
        },
        "creator" : {
            "@type": "Person",
            "name": "Allan Randall"
        },
        "accountablePerson" : {
            "@type": "Person",
            "name": "Allan Randall"
        },
        "copyrightHolder" : {
            "@type": "Person",
            "name": "Allan Randall"
        },
        "copyrightYear" : "2022",
        "dateCreated": "2022-02-23T20:38:00.00Z",
        "datePublished": "2022-02-23T20:38:00.00Z",
        "dateModified": "2022-02-23T20:38:00.00Z",
        "publisher":{
            "@type":"Organization",
            "name": "Allan Randall",
            "url": "https://allanrandall.com/",
            "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/allanrandall.com\/favicon-32x32.png",
                "width":"32",
                "height":"32"
            }
        },
        "image": 
      [
      ]

    ,
        "url" : "https:\/\/allanrandall.com\/posts\/covid\/",
        "wordCount" : "1397",
        "genre" : [ ],
        "keywords" : [ 
      
      "opencv"

    ]
    }
  </script>


</head>
<body class="body">
    <div class="wrapper">
      <aside
        
          class="wrapper__sidebar"
        
      ><div
  class="sidebar
    animated fadeInDown
  "
>
  <div class="sidebar__content">
    <div class="sidebar__introduction">
      <img
        class="sidebar__introduction-profileimage"
        src="https://www.gravatar.com/avatar/e03c396094883ef16085c6c65bd33505?s=240"
        alt="profile picture"
      />
      
        <div class="sidebar__introduction-title">
          <a href="/">Allan Randall</a>
        </div>
      
      <div class="sidebar__introduction-description">
        <p>Hi there! I'm a software engineer living in Melbourne, Australia.</p>
      </div>
    </div>
    <ul class="sidebar__list">
      
        <li class="sidebar__list-item">
          <a
            href="https://www.linkedin.com/in/allanau/"
            target="_blank"
            rel="noopener me"
            aria-label="Linkedin"
            title="Linkedin"
          >
            <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      
        <li class="sidebar__list-item">
          <a
            href="https://github.com/arandall"
            target="_blank"
            rel="noopener me"
            aria-label="Github"
            title="Github"
          >
            <i class="fab fa-github fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      
    </ul>
  </div><footer class="footer footer__sidebar">
  <ul class="footer__list">
    <li class="footer__item">
      &copy;
      
        Allan Randall
        2023
      
    </li>
    
  </ul>
</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js"
    integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ="
    crossorigin="anonymous"
  ></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9BR3BLS2S8"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-9BR3BLS2S8', { 'anonymize_ip': false });
}
</script>
</div>
</aside>
      <main
        
          class="wrapper__main"
        
      >
        <header class="header"><div
  class="
    animated fadeInDown
  "
>
  <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
    <span aria-hidden="true" class="navbar-burger__line"></span>
    <span aria-hidden="true" class="navbar-burger__line"></span>
    <span aria-hidden="true" class="navbar-burger__line"></span>
  </a>
  <nav class="nav">
    <ul class="nav__list" id="navMenu">
      
      
    </ul>
    <ul class="nav__list nav__list--end">
      
      
        <li class="nav__list-item">
          <div class="themeswitch">
            <a title="Switch Theme">
              <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a>
          </div>
        </li>
      
    </ul>
  </nav>
</div>
</header>
  <div
    class="post 
      animated fadeInDown
    "
  >
    
    <div class="post__content">
      <h1>Detecting COVID-19 and Pneumonia Using Transfer Learning</h1>
      <p>This post is an explanation on how I derived my solution to Project 3: Train and Deploy a Radiology AI from <a href="https://opencv.org/course-computer-vision-two/">Computer Vision 2</a>.</p>
<h2 id="the-problem">The Problem</h2>
<p>Given a pre-labeled dataset of images train a model that can predict the following with &gt;95% accuracy.</p>
<ul>
<li>Normal</li>
<li>Pneumonia</li>
<li>COVID19</li>
</ul>
<h2 id="initial-changes-made-to-radiologyai-notebook">Initial changes made to RadiologyAI notebook</h2>
<p>The provided notebook required a number of changes before I was able to move to defining a trainable model. The main reason for this was the original notebook was a binary classification problem detecting lungs that were either normal or suffering from pneumonia.</p>
<p>The changes required to also include COVID-19 were:</p>
<ol>
<li>Updating the download URL to use the Dropbox link provided.</li>
<li>Updating the <code>/content/chest_xray</code> path to <code>/content/Dataset</code></li>
<li>Changing the Last Dense layer from 2 units to 3 as the dataset provided is 3 classes (not the original 2)</li>
</ol>
<p>After these changes the notebook sprung to life returning an unimpressive .3281 val_accuracy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>pretrained_model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>applications<span style="color:#f92672">.</span>c(weights <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;imagenet&#39;</span>,
</span></span><span style="display:flex;"><span>                                                   classes <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>,
</span></span><span style="display:flex;"><span>                                                   input_shape <span style="color:#f92672">=</span> (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">3</span>),
</span></span><span style="display:flex;"><span>                                                   include_top <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                                                   pooling <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;max&#39;</span>)
</span></span><span style="display:flex;"><span>predictions <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">3</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;softmax&#39;</span>)(pretrained_model<span style="color:#f92672">.</span>output)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Epoch 1/5
</span></span><span style="display:flex;"><span>177/177 [==============================] - 149s 821ms/step - loss: 0.6929 - accuracy: 0.3419 - val_loss: 0.6931 - val_accuracy: 0.3263
</span></span><span style="display:flex;"><span>Epoch 2/5
</span></span><span style="display:flex;"><span>177/177 [==============================] - 143s 806ms/step - loss: 0.6928 - accuracy: 0.3499 - val_loss: 0.6928 - val_accuracy: 0.3639
</span></span><span style="display:flex;"><span>Epoch 3/5
</span></span><span style="display:flex;"><span>177/177 [==============================] - 142s 802ms/step - loss: 0.6928 - accuracy: 0.3400 - val_loss: 0.6929 - val_accuracy: 0.3372
</span></span><span style="display:flex;"><span>Epoch 4/5
</span></span><span style="display:flex;"><span>177/177 [==============================] - 142s 800ms/step - loss: 0.6929 - accuracy: 0.3446 - val_loss: 0.6930 - val_accuracy: 0.3166
</span></span><span style="display:flex;"><span>Epoch 5/5
</span></span><span style="display:flex;"><span>177/177 [==============================] - 142s 800ms/step - loss: 0.6928 - accuracy: 0.3521 - val_loss: 0.6929 - val_accuracy: 0.3281
</span></span></code></pre></div><p><img src="mobilenet-only-normalised.png" alt="MobileNet model as is"></p>
<h2 id="creating-a-model">Creating a Model</h2>
<p>Using transfer learning I then set out to define a new fully connected layer with trainable parameters to get a higher degree of accuracy. The biggest question now is, what should it look like?</p>
<p>I spend many hours trying different models, from those included in the course to suggestions from many papers. In the end I discovered a paper by the University of Valladolid<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> which had a clear suggestion. It was relatively small and simple and I thought it should be repeatable.</p>
<p>Taking what I understood from the paper I ended up with the python code below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>pretrained_model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>applications<span style="color:#f92672">.</span>EfficientNetB4(include_top <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>, 
</span></span><span style="display:flex;"><span>                                                   weights <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;imagenet&#39;</span>, 
</span></span><span style="display:flex;"><span>                                                   input_shape <span style="color:#f92672">=</span> (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">3</span>), 
</span></span><span style="display:flex;"><span>                                                   pooling <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;max&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> pretrained_model<span style="color:#f92672">.</span>layers:
</span></span><span style="display:flex;"><span>  layer<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>Sequential()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(pretrained_model)
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">128</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(layers<span style="color:#f92672">.</span>Dropout(<span style="color:#ae81ff">0.3</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">64</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(layers<span style="color:#f92672">.</span>Dropout(<span style="color:#ae81ff">0.3</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">32</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(layers<span style="color:#f92672">.</span>Dropout(<span style="color:#ae81ff">0.3</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">3</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Change from SGD optimizer to Adam with learning rate of .0001</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>compile(optimizer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>optimizers<span style="color:#f92672">.</span>Adam(<span style="color:#ae81ff">0.0001</span>),
</span></span><span style="display:flex;"><span>              loss <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;binary_crossentropy&#34;</span>,
</span></span><span style="display:flex;"><span>              metrics <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;accuracy&#34;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(train_datagen,
</span></span><span style="display:flex;"><span>                    epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">11</span>,
</span></span><span style="display:flex;"><span>                    steps_per_epoch <span style="color:#f92672">=</span> (len(train_datagen)),
</span></span><span style="display:flex;"><span>                    validation_data <span style="color:#f92672">=</span> val_datagen,
</span></span><span style="display:flex;"><span>                    validation_steps <span style="color:#f92672">=</span> (len(val_datagen)),
</span></span><span style="display:flex;"><span>                    shuffle <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                    callbacks <span style="color:#f92672">=</span> callback)
</span></span></code></pre></div><p>As the course mentioned that leaning on prior work was a good starting point I was feeling rather confident until the epochs started rolling by.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Epoch 1/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 197s 951ms/step - loss: 0.7495 - accuracy: 0.3286 - val_loss: 0.6480 - val_accuracy: 0.3518 - lr: 1.0000e-04
</span></span><span style="display:flex;"><span>Epoch 2/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 161s 909ms/step - loss: 0.6584 - accuracy: 0.3327 - val_loss: 0.6482 - val_accuracy: 0.3204 - lr: 1.0000e-04
</span></span><span style="display:flex;"><span>Epoch 3/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 160s 905ms/step - loss: 0.6551 - accuracy: 0.3315 - val_loss: 0.6399 - val_accuracy: 0.3278 - lr: 1.0000e-04
</span></span></code></pre></div><h2 id="better-accuracy">Better Accuracy</h2>
<p>I spent a lot of time scratching my head wondering what I was doing wrong until two things hit me.</p>
<ol>
<li>Lungs are not symmetrical, I shouldn&rsquo;t be flipping them!</li>
<li>The pre-trained images were trained on object classification problems maybe I need to fine tune it.</li>
</ol>
<h3 id="symmetry-of-the-human-body">Symmetry of the Human Body</h3>
<p>This came to me when I was pondering what options I had left to increase accuracy.</p>
<p>I remembered that the left lung had less space, that would be different. In search for confirmation I found a page on AppliedRadiology.com<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> showing some challenges of different parts of the body including the chest.</p>
<blockquote>
<p>Because the heart lies asymmetrically to the left in the thorax, determining right from left in the thorax is not a problem except in the rare case of situs inversus.</p>
</blockquote>
<p>To solve this was quite easy and was something I overlooked when first looking at the notebook thinking, &ldquo;lungs are symmetrical that should be ok.&rdquo;</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train_val_gen <span style="color:#f92672">=</span> ImageDataGenerator(zca_epsilon <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>,
</span></span><span style="display:flex;"><span>                                   horizontal_flip <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                                   rescale <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>)        <span style="color:#75715e"># Do not change rescale</span>
</span></span></code></pre></div><p>With this change alone the accuracy didn&rsquo;t really change suggesting something else was needed.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Epoch 1/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 171s 880ms/step - loss: 2.8510 - accuracy: 0.3282 - val_loss: 1.8354 - val_accuracy: 0.3278
</span></span><span style="display:flex;"><span>Epoch 2/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 151s 851ms/step - loss: 2.6794 - accuracy: 0.3307 - val_loss: 1.6513 - val_accuracy: 0.3278
</span></span><span style="display:flex;"><span>Epoch 3/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 151s 850ms/step - loss: 2.5755 - accuracy: 0.3326 - val_loss: 1.4867 - val_accuracy: 0.3278
</span></span></code></pre></div><p>In hindsight this ended up being a distraction but did result in a slightly higher accuracy.</p>
<h3 id="fine-tuning">Fine Tuning</h3>
<p>When first reading though the problem I thought that I could solve it purely with transfer learning. Reading more and revisiting the course material I concluded the next logical step would be to retrain all or part of the convolutional layers.</p>
<p>The University of Valladolid<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> paper that I had based my model on up until now retrained the EfficientNetB4 layers but when I tried to do the same by removing the following lines a <code>ResourceExhaustedError</code> occurred in Google Colab:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> pretrained_model<span style="color:#f92672">.</span>layers:
</span></span><span style="display:flex;"><span>  layer<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span></code></pre></div><p>Given the paper had high accuracies listed for other models I ended up landing on using the VGG19 model and retraining the last convolutional network using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> pretrained_model<span style="color:#f92672">.</span>layers:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> layer<span style="color:#f92672">.</span>name <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;block5_conv1&#39;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>  layer<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span></code></pre></div><p>The result!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Epoch 1/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 174s 973ms/step - loss: 0.3729 - accuracy: 0.7653 - val_loss: 0.1565 - val_accuracy: 0.9244
</span></span><span style="display:flex;"><span>Epoch 2/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 962ms/step - loss: 0.1783 - accuracy: 0.9201 - val_loss: 0.1382 - val_accuracy: 0.9397
</span></span><span style="display:flex;"><span>Epoch 3/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 960ms/step - loss: 0.1188 - accuracy: 0.9500 - val_loss: 0.1329 - val_accuracy: 0.9453
</span></span><span style="display:flex;"><span>Epoch 4/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 962ms/step - loss: 0.0995 - accuracy: 0.9583 - val_loss: 0.1941 - val_accuracy: 0.9272
</span></span><span style="display:flex;"><span>Epoch 5/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 171s 967ms/step - loss: 0.0776 - accuracy: 0.9671 - val_loss: 0.1278 - val_accuracy: 0.9614
</span></span><span style="display:flex;"><span>Epoch 6/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 958ms/step - loss: 0.0666 - accuracy: 0.9742 - val_loss: 0.1332 - val_accuracy: 0.9574
</span></span><span style="display:flex;"><span>Epoch 7/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 959ms/step - loss: 0.0499 - accuracy: 0.9801 - val_loss: 0.1439 - val_accuracy: 0.9639
</span></span><span style="display:flex;"><span>Epoch 8/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 169s 956ms/step - loss: 0.0503 - accuracy: 0.9808 - val_loss: 0.1415 - val_accuracy: 0.9577
</span></span><span style="display:flex;"><span>Epoch 9/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 958ms/step - loss: 0.0415 - accuracy: 0.9826 - val_loss: 0.1433 - val_accuracy: 0.9636
</span></span><span style="display:flex;"><span>Epoch 10/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 962ms/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.1496 - val_accuracy: 0.9661
</span></span><span style="display:flex;"><span>Epoch 11/11
</span></span><span style="display:flex;"><span>177/177 [==============================] - 170s 960ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.1776 - val_accuracy: 0.9670
</span></span></code></pre></div><p><img src="retrain-conv-confusion-normalised.png" alt="ncm"></p>
<p>A massive improvement! Giving me the confidence I was on the right track. Now to consolidate all that I had learnt.</p>
<h2 id="final-solution">Final Solution</h2>
<p>In the end I settled on the following model parameters which produced a pretty good result.</p>
<ul>
<li>Using the VGG19 pretrained model</li>
<li>Training the last convolutional</li>
<li>Setting <code>horizontal_flip</code> to <code>False</code></li>
<li>3 dense layers with relu activation</li>
<li>Adam optimizer</li>
<li>11 epochs (possibly fewer would&rsquo;ve been enough)</li>
</ul>
<p><img src="final-acc.png" alt="training vs validation"></p>
<p><img src="final-normalised-confusion.png" alt="Normalized Confusion Matrix"></p>
<h2 id="conclusion">Conclusion</h2>
<p>I was a little concerned using 11 epochs that I was getting in the realm of overfitting to the training data however there were some benefits and val_accuracy was still declining. I suspect with some more experience training models I may be able to tune things a bit more but my biggest learnings from this project was:</p>
<ul>
<li>The largest accuracy happen in the early epochs, if things look bad, stop and reevaluate. There is no need to run until the end.</li>
<li>Another pre-trained model might have performed better could&rsquo;ve run multiple to see, decided not to invest more time</li>
</ul>
<p>The next step would be to take my model and compare it with other pretrained models but I decided that it was time to put this problem asside and test the accuracy using the external dataset provided.</p>
<p><img src="streamlit-result.png" alt="External Dataset Result"></p>
<p><strong>&gt;97% Alright!</strong></p>
<h2 id="references">References</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7836808/">Automated medical diagnosis of COVID-19 through EfficientNet convolutional neural network</a> - Gonçalo Marques,⁎ Deevyankar Agarwal, and Isabel de la Torre Díez&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://appliedradiology.com/articles/knowing-right-from-left-on-x-rays-a-way-to-minimize-errors-of-laterality">Knowing right from left on X-rays: A way to minimize errors of laterality</a> - Carl E. Fabian, MD, FACR&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
</div>
    <div class="post__footer">
      

      
        <span><a class="tag" href="/tags/opencv/">opencv</a></span>


      
    </div>

    
  </div>

      </main>
    </div><footer class="footer footer__base">
  <ul class="footer__list">
    <li class="footer__item">
      &copy;
      
        Allan Randall
        2023
      
    </li>
    
  </ul>
</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js"
    integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ="
    crossorigin="anonymous"
  ></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9BR3BLS2S8"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-9BR3BLS2S8', { 'anonymize_ip': false });
}
</script>
</body>
</html>
